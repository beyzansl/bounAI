{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range=90, \n",
    "                                     brightness_range=[0.1, 0.7],\n",
    "                                     width_shift_range=0.5, \n",
    "                                     height_shift_range=0.5,\n",
    "                                     horizontal_flip=True, \n",
    "                                     vertical_flip=True,\n",
    "                                     validation_split=0.15,\n",
    "                                     preprocessing_function=preprocess_input) # VGG16 preprocessing\n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'archive (2)/Animal Image Dataset/train'\n",
    "test_data_dir = 'archive (2)/Animal Image Dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10954 images belonging to 12 classes.\n",
      "Found 1927 images belonging to 12 classes.\n",
      "Found 4296 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "traingen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(128, 128),\n",
    "                                               subset='training',\n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "validgen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(128, 128),\n",
    "                                               subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_generator.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(128, 128),\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
    "\n",
    "    \n",
    "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
    "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
    "    conv_base = VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "    \n",
    "    # Defines how many layers to freeze during training.\n",
    "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
    "    # depending on the size of the fine-tuning parameter.\n",
    "    if fine_tune > 0:\n",
    "        for layer in conv_base.layers[:-fine_tune]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        for layer in conv_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)\n",
    "optim_1 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "n_classes=12\n",
    "\n",
    "n_steps = traingen.samples // BATCH_SIZE\n",
    "n_val_steps = validgen.samples // BATCH_SIZE\n",
    "n_epochs = 5\n",
    "\n",
    "vgg_model = create_model(input_shape, n_classes, optim_1, fine_tune=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                98316     \n",
      "=================================================================\n",
      "Total params: 14,813,004\n",
      "Trainable params: 98,316\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "171/171 [==============================] - 688s 4s/step - loss: 10.8935 - accuracy: 0.3244 - val_loss: 8.3474 - val_accuracy: 0.4615\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 667s 4s/step - loss: 7.3676 - accuracy: 0.5045 - val_loss: 8.5501 - val_accuracy: 0.4823\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 676s 4s/step - loss: 7.5473 - accuracy: 0.5187 - val_loss: 8.2213 - val_accuracy: 0.5318\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 674s 4s/step - loss: 7.4623 - accuracy: 0.5397 - val_loss: 8.5195 - val_accuracy: 0.5276\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 671s 4s/step - loss: 7.4128 - accuracy: 0.5560 - val_loss: 8.6388 - val_accuracy: 0.5109\n"
     ]
    }
   ],
   "source": [
    "vgg_history = vgg_model.fit(traingen,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=n_epochs,\n",
    "                            validation_data=validgen,\n",
    "                            steps_per_epoch=n_steps,\n",
    "                            validation_steps=n_val_steps,\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_classes = testgen.classes\n",
    "class_indices = traingen.class_indices\n",
    "class_indices = dict((v,k) for k,v in class_indices.items())\n",
    "\n",
    "vgg_preds = vgg_model.predict(testgen)\n",
    "vgg_pred_classes = np.argmax(vgg_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 Model Accuracy without Fine-Tuning: 80.47%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vgg_acc = accuracy_score(true_classes, vgg_pred_classes)\n",
    "print(\"VGG16 Model Accuracy without Fine-Tuning: {:.2f}%\".format(vgg_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
